# awesome-genai-resources (WIP) 
A curated collection of resources, tools, tutorials, papers, courses, models, datasets, and projects related to Generative AI (GenAI). This repository aims to serve as a one-stop hub for everything in the GenAI ecosystem, covering topics like LLMs, diffusion models, prompt engineering, fine-tuning, applications, research trends, and more.

## Research Papers

### Open-Source / Open-Weight Models

*   [**BLOOM (176B)**](https://arxiv.org/abs/2211.05100) – Multilingual, open-access model from the BigScience workshop.
*   **GPT-J (6B)** – EleutherAI’s GPT-3-like model under Apache 2.0. (No single canonical paper; part of EleutherAI's body of work).
*   [**GPT-NeoX-20B**](https://arxiv.org/abs/2204.06745) – EleutherAI’s 20B-parameter open model with permissive licensing.
*   [**LLaMA series (7B–65B)**](https://arxiv.org/abs/2302.13971) – Meta’s foundation models, research-only release.
*   [**Falcon models (7B, 40B, 180B)**](https://arxiv.org/abs/2311.16867) – Developed by Technology Innovation Institute; top-tier open performance.
*   [**Baichuan 2 (7B & 13B)**](https://arxiv.org/abs/2309.10305) – Multilingual open models from Chinese researchers.
*   [**DBRX (132B)**](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm) – Semi-sparse mixture-of-experts model from Databricks/Mosaic.
*   [**Gemma series**](https://arxiv.org/abs/2403.08295) – Google DeepMind’s lightweight open models.
*   [**OpenLLaMA**](https://github.com/openlm-research/open_llama) – Open-source reproduction of LLaMA using RedPajama data.
*   [**Phi-2**](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) – Microsoft's powerful small language model.
*   [**Tiny LLaMA**](https://arxiv.org/abs/2401.02385) - An Open-Source Small Language Model.
*   [**StableLM Zephyr**](https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b) - Stability AI's Zephyr series model.
*   [**Qwen 2**](https://arxiv.org/abs/2407.10671) - Technical report for the Qwen2 model series.
*   [**DeepSeek**](https://arxiv.org/abs/2401.02954) - Scaling Open-Source Language Models with Longtermism.
*   [**Mistral 7B**](https://arxiv.org/abs/2310.06825) and [**Mixtral of Experts**](https://arxiv.org/abs/2401.04088) - Foundational papers for Mistral AI's models.
*   [**Grok-1**](https://x.ai/blog/grok-os) - Open Release of Grok-1 by xAI.
*   [**InternLM2**](https://arxiv.org/abs/2403.17297) - Technical report for the InternLM2 models.
*   [**Yi**](https://arxiv.org/abs/2403.04652) - Open Foundation Models by 01.AI.
*   [**Granite Code Models**](https://arxiv.org/abs/2405.04333) - A Family of Open Foundation Models for Code Intelligence.
*   [**Alpaca**](https://crfm.stanford.edu/2023/03/13/alpaca.html) - A Strong, Replicable Instruction-Following Model from Stanford.
*   [**GPT4All**](https://arxiv.org/abs/2311.04931) - An Ecosystem of Open Source Compressed Language Models.
*   [**RedPajama**](https://arxiv.org/abs/2411.12372) - An Open Dataset for Training Large Language Models.
*   [**MPT-7B-Instruct**](https://huggingface.co/mosaicml/mpt-7b-instruct) - MosaicML's Instruction-following model.
*   [**StarCoder**](https://arxiv.org/abs/2305.06161) - A state-of-the-art language model for code.
*   [**DeepSeek-R1**](https://arxiv.org/abs/2501.10694) - Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.
*   [**Qwen 3-235B**](https://arxiv.org/abs/2505.09388) - Think Deeper, Act Faster.
*   [**Qwen 2.5-72B-Instruct**](https://arxiv.org/abs/2412.15115) - Qwen2.5 Technical Report.
*   [**LLaMA 3.3-70B**](https://arxiv.org/abs/2406.14971) - Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training and Model Merging.
*   [**BitNet b1.58 2B4T**](https://arxiv.org/abs/2504.12285) - Technical Report.
*   [**MAP-Neo-7B**](https://arxiv.org/abs/2405.18694) - Highly Capable and Transparent Bilingual Large Language Model Series.
*   [**Gemma 2**](https://arxiv.org/abs/2408.00118) - Improving Open Language Models at a Practical Size.
*   [**Gemma 3**](https://arxiv.org/abs/2503.19786) - Technical Report.
*   [**Phi-4**](https://arxiv.org/abs/2412.08905) - Technical Report.
*   [**StableLM 2**](https://arxiv.org/abs/2402.17834) - 1.6B Technical Report.
*   [**DeepSeek-V3**](https://arxiv.org/abs/2412.19437) - Technical Report.
*   [**StarCoder2**](https://arxiv.org/abs/2402.19173) - The Next Generation.

### Proprietary / Closed-Source Models

*   [**OpenAI’s GPT-4**](https://arxiv.org/abs/2303.08774) - Technical Report for GPT-4.
*   [**Anthropic’s Claude 3**](https://www.anthropic.com/news/the-claude-3-model-family-opus-sonnet-haiku) - Announcement and details for the Claude 3 model family.
*   [**Google’s Gemini**](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) - Technical report for the Gemini model family.
*   [**xAI’s Grok**](https://x.ai/blog/grok-os) - Information on the Grok model.
*   [**AWS Titan**](https://aws.amazon.com/bedrock/titan/) - AWS documentation for Titan models.
*   [**AI21 Labs’ Jurassic-2**](https://www.ai21.com/blog/introducing-jamba-the-first-production-grade-mamba-based-model) - This blog introduces latest architecture.
*   [**Cohere's Command R+**](https://cohere.com/blog/command-r-plus-a-scalable-llm-built-for-business) - The blog post for their Command R+ model.
*   [**Inflection's Pi**](https://inflection.ai/inflection-2-5) - The announcement for Inflection-2.5, the model powering Pi.
*   [**Baidu's ERNIE 4.0**](https://arxiv.org/abs/2310.17128) - Technical report for ERNIE 4.0.
*   [**GPT-4o**](https://arxiv.org/abs/2410.21276) - System Card.
*   [**GPT-4.1**](https://arxiv.org/abs/2507.13945) - Sets the Standard in Automated Experiment Design Using Novel Python Libraries.
*   [**GPT-4.5**](https://openai.com/index/gpt-4-5/) - Research Preview.
*   [**o3-mini & o4-mini**](https://arxiv.org/abs/2501.17749) - Early External Safety Testing of OpenAI's o3-mini.
*   [**Claude 4 Opus & Claude 4 Sonnet**](https://www.anthropic.com/news/system-card-claude-opus-4-claude-sonnet-4) - System Card.
*   [**Grok 3**](https://www.researchgate.net/publication/389881061_Grok_3_A_Threat_to_Human-AI_Interaction_and_Technological_Control) - An analysis of the model.
*   [**Gemini 2.5 Pro**](https://storage.googleapis.com/deepmind-media/gemini/gemini_2_5_report.pdf) - Technical Report.

*Note: For some models, a foundational research paper is not available. In these cases, links point to official blog posts, announcements or related research.*
